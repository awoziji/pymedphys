{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pydicom\n",
    "\n",
    "#import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import functools\n",
    "\n",
    "import skimage.draw\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('hsv')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "import random\n",
    "\n",
    "import timeit\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR INPUT GENERATOR\n",
    "dataset_path = \"/home/matthew/priv/PROSTATE_TEST/\"\n",
    "#structure_names = [\"patient\", \"RT HOF\", \"LT HOF\", \"BLADDER\", \"RECTUM\", \"Couch Foam Half Couch\", \"Couch Outer Half Couch\", \"Couch Edge\"]\n",
    "structure_names = [\"patient\"]\n",
    "\n",
    "context = 10\n",
    "batch_size = 2\n",
    "\n",
    "train_ratio = 0.7 \n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# FOR MODEL BUILDING\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "\n",
    "# GLOBAL VARS\n",
    "input_shape = (2*context + 1, 512, 512, 1)\n",
    "output_shape = (1, 512, 512, len(structure_names))\n",
    "output_channels = output_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PATHS FOR GENERATOR\n",
    "start = timeit.default_timer()\n",
    "\n",
    "patient_paths = glob.glob(dataset_path + \"/*\")\n",
    "\n",
    "context_paths = glob.glob(dataset_path + \"/*/*CT*\", recursive=True)\n",
    "context_paths.sort()\n",
    "\n",
    "input_paths = [glob.glob(path + \"/*CT*\")[context:-context] for path in patient_paths]\n",
    "input_paths = [item for sublist in input_paths for item in sublist]\n",
    "random.shuffle(input_paths)\n",
    "\n",
    "label_paths = glob.glob(dataset_path + \"/*/*RS*\", recursive=True)\n",
    "\n",
    "assert len(context_paths) - (len(label_paths) * 2 * context) == len(input_paths)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "end = timeit.default_timer()\n",
    "print(f\"Time to generate paths (s): {end-start}\")\n",
    "print(\"-------\")\n",
    "for path in patient_paths: print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = input_paths[0:50]\n",
    "\n",
    "num = len(input_paths)\n",
    "num_train = int(num*train_ratio // 1)\n",
    "num_valid = int(num*valid_ratio // 1)\n",
    "num_test = int(num*test_ratio // 1)\n",
    "\n",
    "print(f\"Total: {num} = Train: {num_train} + Valid: {num_valid} + Test: {num_test}\")\n",
    "\n",
    "train_paths = input_paths[0:num_train]\n",
    "valid_paths = input_paths[num_train:num_train+num_valid]\n",
    "test_paths = input_paths[num_train+num_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, input_paths, context_paths, label_paths, batch_size, structure_names):\n",
    "        self.input_paths = input_paths\n",
    "        self.context_paths = context_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.structure_names = structure_names\n",
    "        \n",
    "        for path in self.label_paths:\n",
    "            _ = self.pre_cached_structures(path)\n",
    "\n",
    "        \n",
    "    @functools.lru_cache()\n",
    "    def pre_cached_structures(self, path):\n",
    "        return pydicom.dcmread(path, force=True)\n",
    "    \n",
    "    \n",
    "    def get_parent_dir(self, path):\n",
    "        return Path(path).parent.name\n",
    "\n",
    "        \n",
    "    def __getitem__(self, batch_index, context = 10):\n",
    "        \n",
    "        if(batch_index+1)*self.batch_size > len(self.input_paths):\n",
    "            self.batch_size = len(self.input_paths) - batch_index*self.batch_size\n",
    "        \n",
    "        batch_paths = self.input_paths[batch_index*self.batch_size : (batch_index+1)*self.batch_size]\n",
    "\n",
    "        batch_inputs = []\n",
    "        batch_labels  = []\n",
    "        \n",
    "        for image_path in batch_paths:\n",
    "            # Get parent dir\n",
    "            parent_dir = self.get_parent_dir(image_path)\n",
    "            # Get mask path\n",
    "            mask_path = [s for s in self.label_paths if parent_dir in s][0]\n",
    "            # Get index\n",
    "            image_index = self.context_paths.index(image_path)\n",
    "            # Get context\n",
    "            input_paths = self.context_paths[image_index-context:image_index+context+1]\n",
    "    \n",
    "            ###################### IMAGE LOOP ###################################\n",
    "            \n",
    "            images = []\n",
    "            for dcm_path in input_paths:\n",
    "                dicom_ct = pydicom.dcmread(dcm_path, force=True)\n",
    "                try:\n",
    "                    dicom_ct.file_meta.TransferSyntaxUID\n",
    "                except AttributeError:\n",
    "                    dicom_ct.file_meta.TransferSyntaxUID = (pydicom.uid.ImplicitVRLittleEndian)\n",
    "                image = dicom_ct.pixel_array\n",
    "                images = images + [image]\n",
    "            batch_inputs.append(images)\n",
    "            \n",
    "            ####################### MASK LOOP ####################################\n",
    "\n",
    "            img = pydicom.dcmread(image_path, force=True)\n",
    "            img_position = img.ImagePositionPatient\n",
    "            img_spacing = [x for x in img.PixelSpacing] + [img.SliceThickness]\n",
    "            img_orientation = img.ImageOrientationPatient\n",
    "            \n",
    "#             start_read = timeit.default_timer()\n",
    "#             dcm_rs = pydicom.dcmread(mask_path, force=True)\n",
    "#             end_read = timeit.default_timer()           \n",
    "#             print(f\"Time to read UN-cached struct (s): {end_read-start_read}\")\n",
    "\n",
    "            dcm_rs = self.pre_cached_structures(mask_path)\n",
    "            end_read = timeit.default_timer()           \n",
    "            \n",
    "            dcm_rs_struct_names = [structure.ROIName for structure in dcm_rs.StructureSetROISequence]\n",
    "            \n",
    "            # Pass this as arg!\n",
    "            structure_names = self.structure_names\n",
    "\n",
    "            names_to_pull = [name for name in dcm_rs_struct_names if name in structure_names]\n",
    "            try:\n",
    "                assert len(names_to_pull) == len(structure_names)\n",
    "            except:\n",
    "                batch_inputs.pop()\n",
    "                continue\n",
    "                \n",
    "            structure_indexes = [dcm_rs_struct_names.index(name) for name in names_to_pull]\n",
    "            assert img.FrameOfReferenceUID == dcm_rs.StructureSetROISequence[0].ReferencedFrameOfReferenceUID\n",
    "            \n",
    "            mask = np.zeros(shape=(1, 512, 512, len(structure_indexes)))\n",
    "\n",
    "            dx, dy, *rest = img_spacing\n",
    "            Cx, Cy, *rest = img_position\n",
    "            Ox, Oy =  img_orientation[0], img_orientation[4]\n",
    "\n",
    "            dicom_structures = dcm_rs\n",
    "\n",
    "            for mask_index, structure_index in enumerate(structure_indexes):\n",
    "                z = [z_slice.ContourData[2::3][0] for z_slice in dicom_structures.ROIContourSequence[structure_index].ContourSequence]\n",
    "    \n",
    "                try:\n",
    "                    indexes = z.index(img_position[2])\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "                try:\n",
    "                    len(indexes)\n",
    "                except:\n",
    "                    indexes = [indexes]\n",
    "        \n",
    "\n",
    "                for index in indexes:\n",
    "                    xyz = dicom_structures.ROIContourSequence[structure_index].ContourSequence[index].ContourData\n",
    "               \n",
    "                    x = np.array(xyz[0::3])\n",
    "                    y = np.array(xyz[1::3])\n",
    "        \n",
    "                    r = (y - Cy) / dy * Oy\n",
    "                    c = (x - Cx) / dx * Ox\n",
    "\n",
    "                    rr, cc = skimage.draw.polygon(r, c)\n",
    "        \n",
    "                    mask[:, rr, cc, mask_index] = True\n",
    "            \n",
    "            batch_labels.append(mask)\n",
    "            \n",
    "        ###################### RETURNS ###################################    \n",
    "        batch_inputs = np.array(batch_inputs)\n",
    "        batch_inputs = batch_inputs[..., np.newaxis]    \n",
    "        \n",
    "        batch_input = np.array(batch_inputs)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        return batch_inputs, batch_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.input_paths)/float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gen = DataGen(train_paths, context_paths, label_paths, batch_size = batch_size, structure_names = structure_names)\n",
    "valid_gen = DataGen(valid_paths, context_paths, label_paths, batch_size = batch_size, structure_names = structure_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = randint(0, round(num_train / batch_size))\n",
    "\n",
    "batch_inputs, batch_labels = training_gen.__getitem__(batch_index=batch_index, context=context)\n",
    "\n",
    "print(batch_inputs.shape)\n",
    "print(batch_labels.shape)\n",
    "\n",
    "# [0] to remove batch size\n",
    "# NOTE wants (batch_size, context, 512, 512, 1)\n",
    "assert batch_inputs[0].shape == input_shape\n",
    "# NOTE wants (batch_size, 1, 512, 512, number_of_structures)\n",
    "assert batch_labels[0].shape == output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_in_batch = randint(0, batch_inputs.shape[0]-1)\n",
    "\n",
    "images = batch_inputs[index_in_batch, ..., 0]\n",
    "masks = batch_labels[index_in_batch, 0, ...]\n",
    "\n",
    "num_mask = masks.shape[-1]\n",
    "plt.imshow(images[context], cmap='gray')\n",
    "for i in range(num_mask):\n",
    "    mask = masks[...,i]\n",
    "    if np.max(mask) > 0:\n",
    "        plt.contour(mask, colors = [cmap((i)/num_mask)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def down_block(x, m, n, c, size):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    crop = tf.keras.layers.Cropping3D(cropping=size, data_format=None)(x)\n",
    "    crop = tf.keras.layers.Conv3D(c, 1, activation=None)(crop)\n",
    "\n",
    "    result = tf.keras.layers.ReLU()(x)\n",
    "    for repeat in range(m):\n",
    "        result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(result)\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "    for repeat in range(n):\n",
    "        result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(result)\n",
    "        result = tf.keras.layers.Conv3D(c, (3, 1, 1),\n",
    "                                        strides=1,\n",
    "                                        padding='valid',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(result)\n",
    "        if repeat != range(n)[-1]:\n",
    "            result = tf.keras.layers.ReLU()(result)\n",
    "\n",
    "    result = tf.keras.layers.Add()([crop, result])\n",
    "    return result\n",
    "\n",
    "\n",
    "def pool(x):\n",
    "    result = tf.keras.layers.AveragePooling3D(pool_size=(1, 2, 2),\n",
    "                                              strides=None,\n",
    "                                              padding='valid',\n",
    "                                              data_format='channels_last')(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "def fc_block(x, r):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.layers.Conv3D(1024, (1, 8, 8),\n",
    "                                    strides=1,\n",
    "                                    padding='valid',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False)(x)\n",
    "    for repeat in range(r):\n",
    "        crop = result\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "        result = tf.keras.layers.Add()([crop, result])\n",
    "\n",
    "    result = tf.keras.layers.ReLU()(result)\n",
    "    result = tf.keras.layers.Reshape((1, 8, 8, 256))(x)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def up_block(x, m, c):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    print(\"\\n-----------\\nUPBLOCKING:\")\n",
    "    print(x)\n",
    "\n",
    "    crop = tf.keras.layers.Conv3D(c, 1, activation=None)(x)\n",
    "\n",
    "    result = tf.keras.layers.ReLU()(x)\n",
    "    for repeat in range(m):\n",
    "        result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        data_format='channels_last',\n",
    "                                        use_bias=False)(result)\n",
    "        # result = tf.keras.layers.Conv3DTranspose(c,\n",
    "        #                                          (3,1,1),\n",
    "        #                                          strides= 1,\n",
    "        #                                          data_format='channels_last',\n",
    "        #                                          padding='valid')(result)\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "    result = tf.keras.layers.Add()([crop, result])\n",
    "\n",
    "    print(\"\\nReturn\")\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def upscale(x):\n",
    "    print(\"\\n-----------\\nUPSCALING:\")\n",
    "    print(x)\n",
    "    result = tf.keras.layers.UpSampling3D(size=(1, 2, 2))(x)\n",
    "    print(\"\\nReturn\")\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def stack(x, skip):\n",
    "    # NOTE axis 0 is the batch\n",
    "    print(\"\\n-----------\\nSTACKING:\")\n",
    "    print(x)\n",
    "    print(skip)\n",
    "    result = tf.keras.layers.Concatenate(axis=1)([x, skip])\n",
    "    # result = tf.keras.layers.Concatenate()([x, skip])\n",
    "    print(\"\\nReturn\")\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def Model(input_shape, output_channels):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    skips = []\n",
    "\n",
    "    x = down_block(inputs, 3, 0, 32, 0)\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 3, 0, 32, 0)\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 3, 0, 64, 0)\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 1, 2, 64, (2, 0, 0))\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 1, 2, 128, (2, 0, 0))\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 1, 2, 128, (2, 0, 0))\n",
    "    skips.append(x)\n",
    "    x = pool(x)\n",
    "\n",
    "    x = down_block(x, 0, 4, 256, (4, 0, 0))\n",
    "    skips.append(x)\n",
    "\n",
    "    x = fc_block(x, 2)\n",
    "\n",
    "    print(\n",
    "        \"\\n========================================================\\nBLOCK 1:\")\n",
    "    x = stack(skips[-1], x)\n",
    "    x = up_block(x, 4, 128)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 2:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-2], x)\n",
    "    x = up_block(x, 4, 128)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 3:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-3], x)\n",
    "    x = up_block(x, 4, 64)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 4:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-4], x)\n",
    "    x = up_block(x, 3, 64)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 5:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-5], x)\n",
    "    x = up_block(x, 3, 32)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 6:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-6], x)\n",
    "    x = up_block(x, 3, 32)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nBLOCK 7:\"\n",
    "    )\n",
    "    x = upscale(x)\n",
    "    x = stack(skips[-7], x)\n",
    "    x = up_block(x, 3, 32)\n",
    "\n",
    "    print(\n",
    "        \"\\n=========================================================\\nOUTPUT:\")\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(filters=output_channels,\n",
    "                               kernel_size=(104, 1, 1),\n",
    "                               strides=1,\n",
    "                               padding='valid')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(filters=output_channels,\n",
    "                               kernel_size=(1, 1, 1),\n",
    "                               strides=1,\n",
    "                               activation='sigmoid',\n",
    "                               kernel_initializer='he_normal',\n",
    "                               padding='same')(x)\n",
    "\n",
    "    print(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_shape, output_channels)\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER,\n",
    "              loss = LOSS, \n",
    "              loss_weights=None, \n",
    "              sample_weight_mode=None, \n",
    "              weighted_metrics=None, \n",
    "              target_tensors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = len(input_paths) // batch_size\n",
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=training_gen,\n",
    "                    validation_data=valid_gen,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
