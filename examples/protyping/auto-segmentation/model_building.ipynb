{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATED BUILD OF MODEL"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": null,
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings up u-net model architecture\n",
    "## down block"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": null,
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(down_input, m_2D_convs, n_3D_convs, c_output_channels, crop=None):\n",
    "    \n",
    "    # RELU ACTIVATION LAYERS\n",
    "    # x: Input tensor.\n",
    "    # alpha: float. Slope of the negative part. Defaults to zero.\n",
    "    # max_value: float. Saturation threshold.\n",
    "    # threshold: float. Threshold value for thresholded activation.\n",
    "    \n",
    "    #down = tf.keras.layers.relu(down_input, alpha=0.0, max_value=None, threshold=0.0)\n",
    "    down = tf.keras.layers.Activation(\"relu\")(down_input)\n",
    "    \n",
    "    # CONVOLUTIONAL LAYERS\n",
    "    # filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "    \n",
    "    # kernel_size:\n",
    "    # 2D: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "    # Can be a single integer to specify the same value for all spatial dimensions\n",
    "    # 3D: An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. \n",
    "    # Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    \n",
    "    # strides:\n",
    "    # 2D: An integer or tuple/list of 2 integers, specifying the strides of the convolution \n",
    "    # along the height and width. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    # 3D:  An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial \n",
    "    # dimension. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    \n",
    "    # padding: One of \"valid\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \n",
    "    # \"same\" results in padding the input such that the output has the same length as the original input.\n",
    "    \n",
    "    # activation: Activation function to use (see activations). If you don't specify anything, \n",
    "    # no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "    \n",
    "    # kernel_initializer: Initializer for the kernel weights matrix\n",
    "\n",
    "    for i in range(m_2D_convs):\n",
    "        # repeat m times\n",
    "        \n",
    "        # 2D convolutional layer\n",
    "        # 1*3*3 same convolution\n",
    "        # Rel0 activation\n",
    "        down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            kernel_size=(1,3,3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(down)\n",
    "    \n",
    "    for i in range(n_3D_convs):\n",
    "        # repeat loop n-1 times\n",
    "        \n",
    "        # 3D convolutional layer\n",
    "        # 1*3*3 same convolution\n",
    "        # Rel0 activation\n",
    "        down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (1,3,3) convs\n",
    "                                            kernel_size=(1, 3, 3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(down)\n",
    "        \n",
    "        if i == n_3D_convs - 1: \n",
    "            # 3D convolutional layer\n",
    "            # 1*3*3 valid convolution\n",
    "            # No activation\n",
    "            down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (3,1,1) convs\n",
    "                                            kernel_size=(3, 1, 1),\n",
    "                                            strides=1,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down)\n",
    "        \n",
    "        else:         \n",
    "            # Final 3D convolutional layer\n",
    "            # 1*3*3 valid convolution\n",
    "            # Rel0 activation\n",
    "            down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (3,1,1) convs\n",
    "                                            kernel_size=(3, 1, 1),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down)\n",
    "\n",
    "\n",
    "    \n",
    "    # Crop the image centrally in depth dimension\n",
    "    # could try tf.keras.layers.Cropping3D if this fails\n",
    "    if crop == None:\n",
    "        crop_central_depth = down_input[:]\n",
    "    else:\n",
    "        crop_central_depth = down_input[:, crop[0]:crop[1]]\n",
    "    \n",
    "    # Adapt channels - 1*1*1 conv to c channels\n",
    "    adapt_channels = tf.keras.layers.Conv3D(c_output_channels, (1, 1, 1), activation=None)(crop_central_depth)\n",
    "    \n",
    "    down = tf.keras.layers.Add()([down, adapt_channels])\n",
    "    \n",
    "            \n",
    "    # POOLING LAYERS 3D\n",
    "    # pool_size: tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n",
    "    # strides: tuple of 3 integers, or None. Strides values.\n",
    "    # padding: One of \"valid\" or \"same\" (case-insensitive).\n",
    "    # data_format: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. \n",
    "    # channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \n",
    "    # channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). \n",
    "    # defaults to channels_last\n",
    "    \n",
    "    # 3D Average (not max) pooling layer\n",
    "    # 1*2*2\n",
    "#     if pool == True:\n",
    "#         pool = tf.keras.layers.AveragePooling3D(pool_size=(1, 2, 2), strides=None, padding='valid', data_format='channels_last')(down)\n",
    "#         return down, pool\n",
    "#     else:\n",
    "    return down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pool(down):\n",
    "    pool = tf.keras.layers.AveragePooling3D(pool_size=(1, 2, 2), strides=None, padding='valid', data_format='channels_last')(down)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fc residual block\n",
    "### TODO: See NOTE below"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": null,
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_block(down_input, c_output_channels):\n",
    "    fc = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            kernel_size=(1,8,8),\n",
    "                                            strides=1,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down_input)\n",
    "    \n",
    "    for i in range(2):\n",
    "        short_circuit = fc\n",
    "        fc = tf.keras.layers.Activation(\"relu\")(fc)\n",
    "        \n",
    "        # NOTE: I believe there should be a fully connected layer here\n",
    "        fc = tf.keras.layers.Dense(1024)(fc)\n",
    "        \n",
    "        fc = fc + short_circuit\n",
    "        \n",
    "#         fc = tf.keras.layers.Add()([fc, crop])\n",
    "    \n",
    "    fc = tf.keras.layers.Activation(\"relu\")(fc) \n",
    "    fc = tf.keras.layers.Reshape((1,8,8,256))(fc)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up block\n",
    "### TODO: Tensor shapes returned dont upscale correctly - see model assembly output"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": null,
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(down_input, up_input, m_2D_convs, c_output_channels, upscale=True):\n",
    "    \n",
    "    print(\"up_block\")\n",
    "    \n",
    "    print(\">>>> upblock arg down_in:\", down_input)\n",
    "    print(\">>>> upblock arg up_input:\", up_input)\n",
    "    \n",
    "    if upscale == True:\n",
    "        up = tf.keras.layers.UpSampling3D(size=(1,2,2))(up_input)\n",
    "        print(\">>>> upscale layer:\", up)\n",
    "    else:\n",
    "        up = up_input\n",
    "    \n",
    "    up = tf.keras.layers.concatenate([down_input, up], axis=1)\n",
    "    print(\">>>> concat layer:\", up)\n",
    "    \n",
    "    #crop = up[:]\n",
    "    adapt_channels = tf.keras.layers.Conv3D(c_output_channels, (1, 1, 1), activation=None)(up)\n",
    "    print(\"adapt\", adapt_channels)\n",
    "    \n",
    "    up = tf.keras.layers.Activation(\"relu\")(up)\n",
    "    \n",
    "    for i in range(m_2D_convs):\n",
    "        up = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (1,3,3) convs\n",
    "                                            kernel_size=(1, 3, 3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(up)\n",
    "        print(\">>>> conv layer:\", up)\n",
    "        \n",
    "    up = tf.keras.layers.Add()([up, adapt_channels])\n",
    "    print(\">>>> add layer:\", up)\n",
    "    return up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assembly"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": null,
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape):\n",
    "    \n",
    "    # INPUT PATH\n",
    "    # Input level 1\n",
    "    input_1 = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # ENCODER PATH\n",
    "    # NOTE: Did not specify strides or padding for pooling\n",
    "    # Encoder level 1\n",
    "    down_1 = down_block(input_1, 3, 0, 32)\n",
    "    pool_1 = apply_pool(down_1)\n",
    "    print(\"down1:\", down_1)\n",
    "    print(\"pool1:\", pool_1)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 2\n",
    "    down_2 = down_block(pool_1, 3, 0, 32)\n",
    "    pool_2 = apply_pool(down_2)\n",
    "    print(\"down2:\", down_2)\n",
    "    print(\"pool2:\", pool_2)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 3\n",
    "    down_3 = down_block(pool_2, 3, 0, 64)\n",
    "    pool_3 = apply_pool(down_3)\n",
    "    print(\"down3:\", down_3)\n",
    "    print(\"pool3:\", pool_3)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 4\n",
    "    down_4 = down_block(pool_3, 1, 2, 64, crop=(2,19))\n",
    "    pool_4 = apply_pool(down_4)\n",
    "    print(\"down4:\", down_4)\n",
    "    print(\"pool4:\", pool_4)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 5\n",
    "    down_5 = down_block(pool_4, 1, 2, 128, crop=(4,17))\n",
    "    pool_5 = apply_pool(down_5)\n",
    "    print(\"down5:\", down_5)\n",
    "    print(\"pool5:\", pool_5)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 6\n",
    "    down_6 = down_block(pool_5, 1, 2, 128, crop=(4,17))\n",
    "    pool_6 = apply_pool(down_6)\n",
    "    print(\"down6:\", down_6)\n",
    "    print(\"pool6:\", pool_6)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 7 - No pooling\n",
    "    down_7 = down_block(pool_6, 0, 4, 256, crop=(8,13))\n",
    "    print(\"down7:\", down_7)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # FULLY CONNECTED PATH - level 8\n",
    "    fc_8 = fc_block(down_7, 1024)\n",
    "    print(\"fc8:\", fc_8)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # DECODER PATH\n",
    "    # Decoder level 7 - No upscaling\n",
    "    up_7 = up_block(down_7, fc_8, 4, 128, upscale=False)\n",
    "    print(\"up7:\", up_7)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 6\n",
    "    up_6 = up_block(down_6, up_7, 4, 128)\n",
    "    print(\"up6:\", up_6)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 5\n",
    "    up_5 = up_block(down_5, up_6, 4, 64)\n",
    "    print(\"up5:\", up_5)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 4\n",
    "    up_4 = up_block(down_4, up_5, 3, 64)\n",
    "    print(\"up4:\", up_4)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 3\n",
    "    up_3 = up_block(down_3, up_4, 3, 32)\n",
    "    print(\"up3:\", up_3)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 2\n",
    "    up_2 = up_block(down_2, up_3, 3, 32)\n",
    "    print(\"up2:\", up_2)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 1\n",
    "    up_1 = up_block(down_1, up_2, 3, 32)\n",
    "    print(\"up1:\", up_1)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # OUTPUT PATH\n",
    "    # Output level 1\n",
    "    # 1x1x1 sigmoid activation\n",
    "    output_1 = tf.keras.layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(up_1)\n",
    "    print(\"output\", output_1)\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    return tf.keras.Model(inputs=input_1, outputs=output_1)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down1: Tensor(\"add_8_1/Identity:0\", shape=(None, 21, 512, 512, 32), dtype=float32)\n",
      "pool1: Tensor(\"average_pooling3d_7/Identity:0\", shape=(None, 21, 256, 256, 32), dtype=float32)\n",
      "---------------------\n",
      "down2: Tensor(\"add_9_1/Identity:0\", shape=(None, 21, 256, 256, 32), dtype=float32)\n",
      "pool2: Tensor(\"average_pooling3d_8/Identity:0\", shape=(None, 21, 128, 128, 32), dtype=float32)\n",
      "---------------------\n",
      "down3: Tensor(\"add_10/Identity:0\", shape=(None, 21, 128, 128, 64), dtype=float32)\n",
      "pool3: Tensor(\"average_pooling3d_9/Identity:0\", shape=(None, 21, 64, 64, 64), dtype=float32)\n",
      "---------------------\n",
      "down4: Tensor(\"add_11/Identity:0\", shape=(None, 17, 64, 64, 64), dtype=float32)\n",
      "pool4: Tensor(\"average_pooling3d_10/Identity:0\", shape=(None, 17, 32, 32, 64), dtype=float32)\n",
      "---------------------\n",
      "down5: Tensor(\"add_12/Identity:0\", shape=(None, 13, 32, 32, 128), dtype=float32)\n",
      "pool5: Tensor(\"average_pooling3d_11/Identity:0\", shape=(None, 13, 16, 16, 128), dtype=float32)\n",
      "---------------------\n",
      "down6: Tensor(\"add_13/Identity:0\", shape=(None, 9, 16, 16, 128), dtype=float32)\n",
      "pool6: Tensor(\"average_pooling3d_12/Identity:0\", shape=(None, 9, 8, 8, 128), dtype=float32)\n",
      "---------------------\n",
      "down7: Tensor(\"add_14/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "---------------------\n",
      "fc8: Tensor(\"reshape_1/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_14/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"reshape_1/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate/Identity:0\", shape=(None, 2, 8, 8, 256), dtype=float32)\n",
      "adapt Tensor(\"conv3d_84/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_85/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_86/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_87/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_88/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_15_1/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      "up7: Tensor(\"add_15_1/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_13/Identity:0\", shape=(None, 9, 16, 16, 128), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_15_1/Identity:0\", shape=(None, 2, 8, 8, 128), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d/Identity:0\", shape=(None, 2, 16, 16, 128), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_1/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      "adapt Tensor(\"conv3d_89/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_90/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_91/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_92/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_93/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_16_1/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      "up6: Tensor(\"add_16_1/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_12/Identity:0\", shape=(None, 13, 32, 32, 128), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_16_1/Identity:0\", shape=(None, 11, 16, 16, 128), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_1/Identity:0\", shape=(None, 11, 32, 32, 128), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_2/Identity:0\", shape=(None, 24, 32, 32, 128), dtype=float32)\n",
      "adapt Tensor(\"conv3d_94/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_95/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_96/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_97/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_98/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_17/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      "up5: Tensor(\"add_17/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_11/Identity:0\", shape=(None, 17, 64, 64, 64), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_17/Identity:0\", shape=(None, 24, 32, 32, 64), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_2/Identity:0\", shape=(None, 24, 64, 64, 64), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_3/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      "adapt Tensor(\"conv3d_99/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_100/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_101/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_102/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_18/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      "up4: Tensor(\"add_18/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_10/Identity:0\", shape=(None, 21, 128, 128, 64), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_18/Identity:0\", shape=(None, 41, 64, 64, 64), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_3/Identity:0\", shape=(None, 41, 128, 128, 64), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_4/Identity:0\", shape=(None, 62, 128, 128, 64), dtype=float32)\n",
      "adapt Tensor(\"conv3d_103/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_104/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_105/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_106/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_19/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      "up3: Tensor(\"add_19/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_9_1/Identity:0\", shape=(None, 21, 256, 256, 32), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_19/Identity:0\", shape=(None, 62, 128, 128, 32), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_4/Identity:0\", shape=(None, 62, 256, 256, 32), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_5/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      "adapt Tensor(\"conv3d_107/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_108/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_109/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_110/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_20/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      "up2: Tensor(\"add_20/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_8_1/Identity:0\", shape=(None, 21, 512, 512, 32), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_20/Identity:0\", shape=(None, 83, 256, 256, 32), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_5/Identity:0\", shape=(None, 83, 512, 512, 32), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_6/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      "adapt Tensor(\"conv3d_111/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_112/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_113/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_114/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_21/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      "up1: Tensor(\"add_21/Identity:0\", shape=(None, 104, 512, 512, 32), dtype=float32)\n",
      "---------------------\n",
      "output Tensor(\"conv3d_115/Identity:0\", shape=(None, 104, 512, 512, 1), dtype=float32)\n",
      "---------------------\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "source": [
    "input_shape = (21, 512, 512,1)\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = 'adam'\n",
    "LOSS = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model\n",
    "### TODO: dicom_process.load_data() - see dicom_process_example TODOs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicom_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-116cf9fa797e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicom_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_data_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicom_process' is not defined"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = dicom_process.load_data()\n",
    "print_data_split(train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b13d4a5edf11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit data to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model.fit(input_train, target_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_train' is not defined"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(input_train, target_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e6a888e19a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note if model performs better on training than test this is likely overfitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Overfitting = memorising training data - does not generalise to other unseen cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 90184c9cc5017638aee4f6267356ad6324e88111
   "source": [
    "# Note if model performs better on training than test this is likely overfitting\n",
    "# Overfitting = memorising training data - does not generalise to other unseen cases\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
