{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATED BUILD OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings up u-net model architecture\n",
    "## down block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(down_input, m_2D_convs, n_3D_convs, c_output_channels, pool=True, crop=None):\n",
    "    \n",
    "    # RELU ACTIVATION LAYERS\n",
    "    # x: Input tensor.\n",
    "    # alpha: float. Slope of the negative part. Defaults to zero.\n",
    "    # max_value: float. Saturation threshold.\n",
    "    # threshold: float. Threshold value for thresholded activation.\n",
    "    \n",
    "    #down = tf.keras.layers.relu(down_input, alpha=0.0, max_value=None, threshold=0.0)\n",
    "    down = tf.keras.layers.Activation(\"relu\")(down_input)\n",
    "    \n",
    "    # CONVOLUTIONAL LAYERS\n",
    "    # filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "    \n",
    "    # kernel_size:\n",
    "    # 2D: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "    # Can be a single integer to specify the same value for all spatial dimensions\n",
    "    # 3D: An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. \n",
    "    # Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    \n",
    "    # strides:\n",
    "    # 2D: An integer or tuple/list of 2 integers, specifying the strides of the convolution \n",
    "    # along the height and width. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    # 3D:  An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial \n",
    "    # dimension. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    \n",
    "    # padding: One of \"valid\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \n",
    "    # \"same\" results in padding the input such that the output has the same length as the original input.\n",
    "    \n",
    "    # activation: Activation function to use (see activations). If you don't specify anything, \n",
    "    # no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "    \n",
    "    # kernel_initializer: Initializer for the kernel weights matrix\n",
    "\n",
    "    for i in range(m_2D_convs):\n",
    "        # repeat m times\n",
    "        \n",
    "        # 2D convolutional layer\n",
    "        # 1*3*3 same convolution\n",
    "        # Rel0 activation\n",
    "        down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            kernel_size=(1,3,3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(down)\n",
    "    \n",
    "    for i in range(n_3D_convs):\n",
    "        # repeat loop n-1 times\n",
    "        \n",
    "        # 3D convolutional layer\n",
    "        # 1*3*3 same convolution\n",
    "        # Rel0 activation\n",
    "        down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (1,3,3) convs\n",
    "                                            kernel_size=(1, 3, 3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(down)\n",
    "        \n",
    "        if i == n_3D_convs - 1: \n",
    "            # 3D convolutional layer\n",
    "            # 1*3*3 valid convolution\n",
    "            # No activation\n",
    "            down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (3,1,1) convs\n",
    "                                            kernel_size=(3, 1, 1),\n",
    "                                            strides=1,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down)\n",
    "        \n",
    "        else:         \n",
    "            # Final 3D convolutional layer\n",
    "            # 1*3*3 valid convolution\n",
    "            # Rel0 activation\n",
    "            down = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (3,1,1) convs\n",
    "                                            kernel_size=(3, 1, 1),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down)\n",
    "\n",
    "\n",
    "    \n",
    "    # Crop the image centrally in depth dimension\n",
    "    # could try tf.keras.layers.Cropping3D if this fails\n",
    "    if crop == None:\n",
    "        crop_central_depth = down_input[:]\n",
    "    else:\n",
    "        crop_central_depth = down_input[:, crop[0]:crop[1]]\n",
    "    \n",
    "    # Adapt channels - 1*1*1 conv to c channels\n",
    "    adapt_channels = tf.keras.layers.Conv3D(c_output_channels, (1, 1, 1), activation=None)(crop_central_depth)\n",
    "    \n",
    "    down = tf.keras.layers.Add()([down, adapt_channels])\n",
    "    \n",
    "            \n",
    "    # POOLING LAYERS 3D\n",
    "    # pool_size: tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n",
    "    # strides: tuple of 3 integers, or None. Strides values.\n",
    "    # padding: One of \"valid\" or \"same\" (case-insensitive).\n",
    "    # data_format: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. \n",
    "    # channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \n",
    "    # channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). \n",
    "    # defaults to channels_last\n",
    "    \n",
    "    # 3D Average (not max) pooling layer\n",
    "    # 1*2*2\n",
    "    if pool == True:\n",
    "        pool = tf.keras.layers.AveragePooling3D(pool_size=(1, 2, 2), strides=None, padding='valid', data_format='channels_last')(down)\n",
    "        return down, pool\n",
    "    else:\n",
    "        return down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fc residual block\n",
    "### TODO: See NOTE below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_block(down_input, c_output_channels):\n",
    "    fc = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            kernel_size=(1,8,8),\n",
    "                                            strides=1,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='valid')(down_input)\n",
    "    \n",
    "    for i in range(2):\n",
    "        crop = fc[:]\n",
    "        fc = tf.keras.layers.Activation(\"relu\")(fc)\n",
    "        \n",
    "        # NOTE: I believe there should be a fully connected layer here\n",
    "        fc = tf.keras.layers.Dense(1024)(fc)\n",
    "        fc = tf.keras.layers.Add()([fc, crop])\n",
    "    \n",
    "    fc = tf.keras.layers.Activation(\"relu\")(fc) \n",
    "    fc = tf.keras.layers.Reshape((1,8,8,256))(fc)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up block\n",
    "### TODO: Tensor shapes returned dont upscale correctly - see model assembly output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(down_input, up_input, m_2D_convs, c_output_channels, upscale=True):\n",
    "    \n",
    "    print(\"up_block\")\n",
    "    \n",
    "    print(\">>>> upblock arg down_in:\", down_input)\n",
    "    print(\">>>> upblock arg up_input:\", up_input)\n",
    "    \n",
    "    if upscale == True:\n",
    "        up = tf.keras.layers.UpSampling3D(size=(1,2,2))(up_input)\n",
    "        print(\">>>> upscale layer:\", up)\n",
    "    else:\n",
    "        up = up_input\n",
    "    \n",
    "    up = tf.keras.layers.concatenate([down_input, up], axis=0)\n",
    "    print(\">>>> concat layer:\", up)\n",
    "    \n",
    "    crop = up[:]\n",
    "    adapt_channels = tf.keras.layers.Conv3D(c_output_channels, (1, 1, 1), activation=None)(crop)\n",
    "    \n",
    "    up = tf.keras.layers.Activation(\"relu\")(up)\n",
    "    \n",
    "    for i in range(m_2D_convs):\n",
    "        up = tf.keras.layers.Conv3D(filters=c_output_channels,\n",
    "                                            # Note: Stated (1,3,3) convs\n",
    "                                            kernel_size=(1, 3, 3),\n",
    "                                            strides=1,\n",
    "                                            activation='relu',\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            padding='same')(up)\n",
    "        print(\">>>> conv layer:\", up)\n",
    "        \n",
    "    up = tf.keras.layers.Add()([up, adapt_channels])\n",
    "    print(\">>>> add layer:\", up)\n",
    "    return up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape):\n",
    "    \n",
    "    # INPUT PATH\n",
    "    # Input level 1\n",
    "    input_1 = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # ENCODER PATH\n",
    "    # NOTE: Did not specify strides or padding for pooling\n",
    "    # Encoder level 1\n",
    "    down_1, pool_1 = down_block(input_1, 3, 0, 32)\n",
    "    print(\"down1:\", down_1)\n",
    "    print(\"pool1:\", pool_1)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 2\n",
    "    down_2, pool_2 = down_block(pool_1, 3, 0, 32)\n",
    "    print(\"down2:\", down_2)\n",
    "    print(\"pool2:\", pool_2)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 3\n",
    "    down_3, pool_3 = down_block(pool_2, 3, 0, 64)\n",
    "    print(\"down3:\", down_3)\n",
    "    print(\"pool3:\", pool_3)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 4\n",
    "    down_4, pool_4 = down_block(pool_3, 1, 2, 64, crop=(2,19))\n",
    "    print(\"down4:\", down_4)\n",
    "    print(\"pool4:\", pool_4)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 5\n",
    "    down_5, pool_5 = down_block(pool_4, 1, 2, 128, crop=(4,17))\n",
    "    print(\"down5:\", down_5)\n",
    "    print(\"pool5:\", pool_5)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 6\n",
    "    down_6, pool_6 = down_block(pool_5, 1, 2, 128, crop=(4,17))\n",
    "    print(\"down6:\", down_6)\n",
    "    print(\"pool6:\", pool_6)\n",
    "    print(\"---------------------\")\n",
    "    # Encoder level 7 - No pooling\n",
    "    down_7 = down_block(pool_6, 0, 4, 256, pool=False, crop=(8,13))\n",
    "    print(\"down7:\", down_7)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # FULLY CONNECTED PATH - level 8\n",
    "    fc_8 = fc_block(down_7, 1024)\n",
    "    print(\"fc8:\", fc_8)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # DECODER PATH\n",
    "    # Decoder level 7 - No upscaling\n",
    "    up_7 = up_block(down_7, fc_8, 4, 256, upscale=False)\n",
    "    print(\"up7:\", up_7)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 6\n",
    "    up_6 = up_block(down_6, up_7, 4, 128)\n",
    "    print(\"up6:\", up_6)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 5\n",
    "    up_5 = up_block(down_5, up_6, 4, 128)\n",
    "    print(\"up5:\", up_5)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 4\n",
    "    up_4 = up_block(down_4, up_5, 3, 64)\n",
    "    print(\"up4:\", up_4)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 3\n",
    "    up_3 = up_block(down_3, up_4, 3, 64)\n",
    "    print(\"up3:\", up_3)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 2\n",
    "    up_2 = up_block(down_2, up_3, 3, 64)\n",
    "    print(\"up2:\", up_2)\n",
    "    print(\"---------------------\")\n",
    "    # Decoder level 1\n",
    "    up_1 = up_block(down_1, up_2, 3, 64)\n",
    "    print(\"up1:\", up_1)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # OUTPUT PATH\n",
    "    # Output level 1\n",
    "    # 1x1x1 sigmoid activation\n",
    "    output_1 = tf.keras.layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(up_1)\n",
    "    print(\"output\", output_1)\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    return tf.keras.Model(inputs=input_1, outputs=output_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down1: Tensor(\"add_80/Identity:0\", shape=(None, 21, 512, 512, 32), dtype=float32)\n",
      "pool1: Tensor(\"average_pooling3d_48/Identity:0\", shape=(None, 21, 256, 256, 32), dtype=float32)\n",
      "---------------------\n",
      "down2: Tensor(\"add_81/Identity:0\", shape=(None, 21, 256, 256, 32), dtype=float32)\n",
      "pool2: Tensor(\"average_pooling3d_49/Identity:0\", shape=(None, 21, 128, 128, 32), dtype=float32)\n",
      "---------------------\n",
      "down3: Tensor(\"add_82/Identity:0\", shape=(None, 21, 128, 128, 64), dtype=float32)\n",
      "pool3: Tensor(\"average_pooling3d_50/Identity:0\", shape=(None, 21, 64, 64, 64), dtype=float32)\n",
      "---------------------\n",
      "down4: Tensor(\"add_83/Identity:0\", shape=(None, 17, 64, 64, 64), dtype=float32)\n",
      "pool4: Tensor(\"average_pooling3d_51/Identity:0\", shape=(None, 17, 32, 32, 64), dtype=float32)\n",
      "---------------------\n",
      "down5: Tensor(\"add_84/Identity:0\", shape=(None, 13, 32, 32, 128), dtype=float32)\n",
      "pool5: Tensor(\"average_pooling3d_52/Identity:0\", shape=(None, 13, 16, 16, 128), dtype=float32)\n",
      "---------------------\n",
      "down6: Tensor(\"add_85/Identity:0\", shape=(None, 9, 16, 16, 128), dtype=float32)\n",
      "pool6: Tensor(\"average_pooling3d_53/Identity:0\", shape=(None, 9, 8, 8, 128), dtype=float32)\n",
      "---------------------\n",
      "down7: Tensor(\"add_86/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "---------------------\n",
      "fc8: Tensor(\"reshape_8/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_86/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"reshape_8/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> concat layer: Tensor(\"concatenate_16/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_401/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_402/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_403/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> conv layer: Tensor(\"conv3d_404/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> add layer: Tensor(\"add_89/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "up7: Tensor(\"add_89/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      "---------------------\n",
      "up_block\n",
      ">>>> upblock arg down_in: Tensor(\"add_85/Identity:0\", shape=(None, 9, 16, 16, 128), dtype=float32)\n",
      ">>>> upblock arg up_input: Tensor(\"add_89/Identity:0\", shape=(None, 1, 8, 8, 256), dtype=float32)\n",
      ">>>> upscale layer: Tensor(\"up_sampling3d_8/Identity:0\", shape=(None, 1, 16, 16, 256), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 9, 16, 16, 128), (None, 1, 16, 16, 256)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c6ec0be154c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-6b29ff7b650e>\u001b[0m in \u001b[0;36munet_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Decoder level 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mup_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"up6:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-7a547fb355d4>\u001b[0m in \u001b[0;36mup_block\u001b[0;34m(down_input, up_input, m_2D_convs, c_output_channels, upscale)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdown_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>>> concat layer:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   \"\"\"\n\u001b[0;32m--> 716\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    399\u001b[0m                            if shape[axis] is not None])\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 9, 16, 16, 128), (None, 1, 16, 16, 256)]"
     ]
    }
   ],
   "source": [
    "input_shape = (21, 512, 512,1)\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = 'adam'\n",
    "LOSS = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-058cedd21ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model\n",
    "### TODO: dicom_process.load_data() - see dicom_process_example TODOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicom_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-116cf9fa797e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicom_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_data_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicom_process' is not defined"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = dicom_process.load_data()\n",
    "print_data_split(train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b13d4a5edf11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit data to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model.fit(input_train, target_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(input_train, target_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e6a888e19a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note if model performs better on training than test this is likely overfitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Overfitting = memorising training data - does not generalise to other unseen cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Note if model performs better on training than test this is likely overfitting\n",
    "# Overfitting = memorising training data - does not generalise to other unseen cases\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
