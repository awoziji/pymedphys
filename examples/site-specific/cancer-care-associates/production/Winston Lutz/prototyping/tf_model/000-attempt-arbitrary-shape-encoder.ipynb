{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import IPython\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def convolve_block(filters, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters, 3, strides=1, padding='same',\n",
    "            kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def Model():\n",
    "    network_stack = [\n",
    "        convolve_block(64, apply_batchnorm=False),\n",
    "        convolve_block(128),\n",
    "        convolve_block(256),\n",
    "        convolve_block(512),\n",
    "        convolve_block(512),\n",
    "        convolve_block(512),\n",
    "        convolve_block(512),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(8),\n",
    "    ]\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=[None,None,1], batch_size=None)\n",
    "    x = inputs\n",
    "\n",
    "    for block in network_stack:\n",
    "        x = block(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymedphys._mocks import wlutz, profiles\n",
    "from pymedphys._wlutz import reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_dataset(grid_size):\n",
    "\n",
    "    while True:\n",
    "        field_centre = tf.random.uniform((2,), -0.5, 0.5)\n",
    "        field_side_lengths = tf.random.uniform((2,), 0.2, 1.5)\n",
    "        field_penumbra = tf.random.uniform((), 0.05, 0.2).numpy()\n",
    "        field_rotation_raw = tf.random.uniform((), -1, 1).numpy()\n",
    "        field_rotation = field_rotation_raw * 180\n",
    "\n",
    "        bb_centre = tf.random.uniform((2,), -0.5, 0.5)\n",
    "        bb_diameter = tf.random.uniform((), 0.05, 0.3).numpy()\n",
    "        bb_max_attenuation = tf.random.uniform((), 0.1, 0.5).numpy()\n",
    "\n",
    "\n",
    "        field = profiles.create_rectangular_field_function(\n",
    "            field_centre, field_side_lengths, field_penumbra, field_rotation\n",
    "        )\n",
    "        bb_penumbra = field_penumbra / 3\n",
    "        bb_attenuation_map = wlutz.create_bb_attenuation_func(\n",
    "            bb_diameter, bb_penumbra, bb_max_attenuation\n",
    "        )\n",
    "\n",
    "        x = np.linspace(-1, 1, grid_size)\n",
    "        xx, yy = np.meshgrid(x, x)\n",
    "\n",
    "        without_bb = field(xx, yy)\n",
    "\n",
    "        def field_with_bb(x, y):\n",
    "            return field(x, y) * bb_attenuation_map(x - bb_centre[0], y - bb_centre[1])\n",
    "\n",
    "        with_bb = field_with_bb(xx, yy)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            log_mean_sqr_diff = np.log(np.mean((without_bb - with_bb)**2))\n",
    "#         print(log_mean_sqr_diff)\n",
    "\n",
    "        if log_mean_sqr_diff > -10:\n",
    "            break\n",
    "            \n",
    "    parameters = tf.concat([field_centre, field_side_lengths, [field_rotation_raw], bb_centre, [bb_diameter]], 0)\n",
    "    img = tf.convert_to_tensor(with_bb, dtype=tf.float32)\n",
    "            \n",
    "    return parameters, img\n",
    "\n",
    "parameters, img = create_single_dataset(128)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(img)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_dataset(batch_size):\n",
    "    def dataset_generator():\n",
    "        image_size_for_current_batch = tf.random.uniform((), 32, 128, dtype=tf.int32).numpy()\n",
    "        for _ in range(batch_size):\n",
    "            yield create_single_dataset(image_size_for_current_batch)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        dataset_generator, \n",
    "        (tf.float32, tf.float32), \n",
    "        (tf.TensorShape([8]), tf.TensorShape([None, None]))\n",
    "    )\n",
    "\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_pipeline_dataset(2)\n",
    "\n",
    "for parameters, img in test_dataset.take(3):    \n",
    "    dim = img.shape\n",
    "    print(dim)\n",
    "    for i in range(dim[0]):        \n",
    "        plt.figure()\n",
    "        plt.pcolormesh(img[i, :, :])\n",
    "        plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters(tensor_parameters):\n",
    "    parameters = {\n",
    "        'field_centre': (tensor_parameters[0], tensor_parameters[1]),\n",
    "        'field_side_lengths': (tensor_parameters[2], tensor_parameters[3]),\n",
    "        'field_rotation': tensor_parameters[4] * 180,\n",
    "        'bb_centre': (tensor_parameters[5], tensor_parameters[6]),\n",
    "        'bb_diameter': tensor_parameters[7]\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(image, field_centre, field_side_lengths, field_rotation, bb_centre, bb_diameter):\n",
    "    dim = image.shape\n",
    "    x = np.linspace(-1, 1, dim[0])\n",
    "    y = x\n",
    "    \n",
    "    return reporting.image_analysis_figure(\n",
    "        x, y, np.array(image),\n",
    "        np.array(bb_centre), np.array(field_centre), np.array(field_rotation),\n",
    "        bb_diameter, field_side_lengths, penumbra=0.2, units=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_figures(model, batch_images, batch_ground_truth_parameters):\n",
    "    batch_dim = batch_images.shape\n",
    "    num_batches = batch_dim[0]\n",
    "    image_shape = dim[1]\n",
    "    x = np.linspace(-1, 1, image_shape)\n",
    "    y = x\n",
    "    \n",
    "    batch_predicted_parameters = model(batch_images, training=True)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        \n",
    "        ground_truth_parameters = extract_parameters(batch_ground_truth_parameters[i, :])\n",
    "        predicted_parameters = extract_parameters(batch_predicted_parameters[i, :])\n",
    "    \n",
    "        fig, axs = create_figure(batch_images[i,:,:], **ground_truth_parameters)\n",
    "        axs[0,0].set_title(\"Ground Truth\")\n",
    "\n",
    "        fig, axs = create_figure(batch_images[i,:,:], **predicted_parameters)\n",
    "        axs[0,0].set_title(\"Predicted\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameters, img in test_dataset.take(1):\n",
    "    results_figures(model, img, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_parameters(tensor_parameters):\n",
    "#     parameters = {\n",
    "#         'field_centre': (tensor_parameters[0], tensor_parameters[1]),\n",
    "#         'field_side_lengths': (tensor_parameters[2], tensor_parameters[3]),\n",
    "#         'field_rotation': tensor_parameters[4] * 180,\n",
    "#         'bb_centre': (tensor_parameters[5], tensor_parameters[6]),\n",
    "#         'bb_diameter': tensor_parameters[7]\n",
    "#     }\n",
    "    \n",
    "#     return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_diff_rotation_and_flipped(predicted_parameters, ground_truth_parameters):\n",
    "    \"\"\"Account for the fact that flipped edge lengths is equivalent to a 90 degree rotation\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_rotations = predicted_parameters[:, 4] * 180\n",
    "    ground_truth_rotations = ground_truth_parameters[:, 4] * 180\n",
    "    \n",
    "    predicted_field_side_lengths = tf.stack([predicted_parameters[:, 2], predicted_parameters[:, 3]])\n",
    "    ground_truth_field_side_lengths = tf.stack([ground_truth_parameters[:, 2], ground_truth_parameters[:, 3]])\n",
    "    \n",
    "    diff_rotation = (predicted_rotations - ground_truth_rotations) % 180\n",
    "    diff_rotation = tf.reduce_min(tf.stack([diff_rotation, 180 - diff_rotation]), axis=0)\n",
    "    \n",
    "    diff_field_side_lengths = tf.reduce_sum(\n",
    "        tf.abs(predicted_field_side_lengths - ground_truth_field_side_lengths),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "#     print(ground_truth_field_side_lengths)\n",
    "#     print(tf.reverse(\n",
    "#             ground_truth_field_side_lengths, [0]))\n",
    "    diff_field_side_lengths_flipped = tf.reduce_sum(\n",
    "        tf.abs(predicted_field_side_lengths - tf.reverse(\n",
    "            ground_truth_field_side_lengths, [0])),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    diff_rotation_flipped = (predicted_rotations - ground_truth_rotations + 90) % 180\n",
    "    diff_rotation_flipped = tf.reduce_min(\n",
    "        tf.stack([diff_rotation_flipped, 180 - diff_rotation_flipped]), \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "#     print(diff_rotation)\n",
    "#     print(diff_field_side_lengths)\n",
    "#     print(diff_rotation_flipped)\n",
    "#     print(diff_field_side_lengths_flipped)\n",
    "    \n",
    "    diff_rotation_and_field_sides = tf.reduce_min(tf.stack([\n",
    "        diff_rotation + diff_field_side_lengths,\n",
    "        diff_rotation_flipped + diff_field_side_lengths_flipped\n",
    "    ]), axis=0)\n",
    "    \n",
    "    return diff_rotation_and_field_sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(predicted_parameters, ground_truth_parameters):\n",
    "    \n",
    "    diff_rotation_and_field_sides = determine_diff_rotation_and_flipped(\n",
    "        predicted_parameters, ground_truth_parameters)\n",
    "    \n",
    "    remaining_predicted = tf.concat([predicted_parameters[:, 0:2], predicted_parameters[:, 5::]], axis=-1)\n",
    "    remaining_ground_truth = tf.concat([ground_truth_parameters[:, 0:2], ground_truth_parameters[:, 5::]], axis=-1)\n",
    "    \n",
    "    remaining_diff = tf.abs(remaining_predicted - remaining_ground_truth)\n",
    "    \n",
    "    diff = tf.concat([diff_rotation_and_field_sides[:, None], remaining_diff], axis=-1)\n",
    "    loss = tf.reduce_mean(diff, axis=-1)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameters, img in test_dataset.take(1):\n",
    "    print(parameters)\n",
    "    print(cost_function(parameters, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def train_step(ground_truth_parameters, input_image, epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_parameters = model(input_image, training=True)\n",
    "        loss = cost_function(predicted_parameters, ground_truth_parameters)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', reduced_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.display.clear_output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for parameters, img in test_ds.take(1):\n",
    "            results_figures(model, img, parameters)\n",
    "\n",
    "        iters_per_epoch = 10\n",
    "        for parameters, img in tqdm.tqdm(train_ds.take(iters_per_epoch), total=iters_per_epoch):\n",
    "            train_step(parameters, img, epoch)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                            time.time()-start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.tqdm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "poetry run tensorboard --logdir examples/site-specific/cancer-care-associates/production/Winston\\ Lutz/prototyping/tf_model/logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAMBDA = 1/30\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_pipeline_dataset(1)\n",
    "train_dataset = create_pipeline_dataset(10)\n",
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
